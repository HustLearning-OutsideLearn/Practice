{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9553d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bucketized_user_age': 45.0,\n",
      " 'movie_genres': array([7], dtype=int64),\n",
      " 'movie_id': b'357',\n",
      " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " 'raw_user_age': 46.0,\n",
      " 'timestamp': 879024327,\n",
      " 'user_gender': True,\n",
      " 'user_id': b'138',\n",
      " 'user_occupation_label': 4,\n",
      " 'user_occupation_text': b'doctor',\n",
      " 'user_rating': 4.0,\n",
      " 'user_zip_code': b'53211'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\")\n",
    "\n",
    "for x in ratings.take(1).as_numpy_iterator():\n",
    "  pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70410f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "movie_title_lookup = tf.keras.layers.StringLookup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f190511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['[UNK]', 'Star Wars (1977)', 'Contact (1997)', 'Fargo (1996)', 'Return of the Jedi (1983)', 'Liar Liar (1997)', 'English Patient, The (1996)', 'Scream (1996)', 'Toy Story (1995)', 'Air Force One (1997)']\n"
     ]
    }
   ],
   "source": [
    "movie_title_lookup.adapt(ratings.map(lambda x: x[\"movie_title\"]))\n",
    "\n",
    "print(f\"Vocabulary: {movie_title_lookup.get_vocabulary()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3aa802d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 1, 58], dtype=int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_lookup([\"Star Wars (1977)\", \"One Flew Over the Cuckoo's Nest (1975)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b797dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a large number of bins to reduce the chance of hash collisions.\n",
    "num_hashing_bins = 200_000\n",
    "\n",
    "movie_title_hashing = tf.keras.layers.Hashing(\n",
    "    num_bins=num_hashing_bins\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba72485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "movie_title_embedding = tf.keras.layers.Embedding(\n",
    "    # Let's use the explicit vocabulary lookup.\n",
    "    input_dim=movie_title_lookup.vocab_size(),\n",
    "    output_dim=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0066fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title_model = tf.keras.Sequential([movie_title_lookup, movie_title_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651ef894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['Star Wars (1977)']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['Star Wars (1977)']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[ 0.02984858, -0.03101732,  0.03185679, -0.02548436, -0.0242424 ,\n",
       "        -0.04666231, -0.02745789, -0.01491805, -0.03062699, -0.0083112 ,\n",
       "         0.00553894,  0.00679458,  0.04705488,  0.02218219,  0.00766157,\n",
       "        -0.02312285, -0.03884612, -0.00157416, -0.00050169, -0.03804217,\n",
       "         0.03130093, -0.01566536, -0.01233972,  0.00178432, -0.01083712,\n",
       "         0.03530444,  0.01749464,  0.03213369,  0.02893731,  0.02817215,\n",
       "         0.02602048, -0.04431283]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_title_model([\"Star Wars (1977)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d8ad80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    }
   ],
   "source": [
    "user_id_lookup = tf.keras.layers.StringLookup()\n",
    "user_id_lookup.adapt(ratings.map(lambda x: x[\"user_id\"]))\n",
    "\n",
    "user_id_embedding = tf.keras.layers.Embedding(user_id_lookup.vocab_size(), 32)\n",
    "\n",
    "user_id_model = tf.keras.Sequential([user_id_lookup, user_id_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2db4b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp: 879024327.\n",
      "Timestamp: 875654590.\n",
      "Timestamp: 882075110.\n"
     ]
    }
   ],
   "source": [
    "for x in ratings.take(3).as_numpy_iterator():\n",
    "  print(f\"Timestamp: {x['timestamp']}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2099f16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized timestamp: [-0.8429372].\n",
      "Normalized timestamp: [-1.4735202].\n",
      "Normalized timestamp: [-0.27203265].\n"
     ]
    }
   ],
   "source": [
    "#Standardization\n",
    "timestamp_normalization = tf.keras.layers.Normalization(\n",
    "    axis=None\n",
    ")\n",
    "timestamp_normalization.adapt(ratings.map(lambda x: x[\"timestamp\"]).batch(1024))\n",
    "\n",
    "for x in ratings.take(3).as_numpy_iterator():\n",
    "  print(f\"Normalized timestamp: {timestamp_normalization(x['timestamp'])}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f1f1855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets: [8.74724710e+08 8.74743291e+08 8.74761871e+08]\n"
     ]
    }
   ],
   "source": [
    "#Discretization\n",
    "max_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(\n",
    "    tf.cast(0, tf.int64), tf.maximum).numpy().max()\n",
    "min_timestamp = ratings.map(lambda x: x[\"timestamp\"]).reduce(\n",
    "    np.int64(1e9), tf.minimum).numpy().min()\n",
    "\n",
    "timestamp_buckets = np.linspace(\n",
    "    min_timestamp, max_timestamp, num=1000)\n",
    "\n",
    "print(f\"Buckets: {timestamp_buckets[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c77d77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp embedding: [[-0.0483192   0.02814445 -0.0286371  -0.03762922  0.04336416  0.00763898\n",
      "   0.02131111 -0.00512896  0.04632627 -0.0403089   0.04948196  0.00499985\n",
      "   0.0099299   0.03291242  0.01129998  0.04861896 -0.03552502 -0.00382494\n",
      "   0.00496203 -0.0303938   0.01234585  0.00761328 -0.00033601 -0.02691567\n",
      "   0.04703413 -0.03365796  0.00911001  0.03557081  0.03773986  0.03304858\n",
      "   0.0161025  -0.0425391 ]].\n"
     ]
    }
   ],
   "source": [
    "timestamp_embedding_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "  tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32)\n",
    "])\n",
    "\n",
    "for timestamp in ratings.take(1).map(lambda x: x[\"timestamp\"]).batch(1).as_numpy_iterator():\n",
    "  print(f\"Timestamp embedding: {timestamp_embedding_model(timestamp)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30fd25f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = tf.keras.layers.TextVectorization()\n",
    "title_text.adapt(ratings.map(lambda x: x[\"movie_title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5f3b878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 32 266 162   2 267 265  53]], shape=(1, 7), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for row in ratings.batch(1).map(lambda x: x[\"movie_title\"]).take(1):\n",
    "  print(title_text(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0a8cfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1959']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_text.get_vocabulary()[99:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        user_id_lookup,\n",
    "        tf.keras.layers.Embedding(user_id_lookup.vocab_size(), 32),\n",
    "    ])\n",
    "    self.timestamp_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "      tf.keras.layers.Embedding(len(timestamp_buckets) + 2, 32)\n",
    "    ])\n",
    "    self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "        axis=None\n",
    "    )\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    # Take the input dictionary, pass it through each input layer,\n",
    "    # and concatenate the result.\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"user_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1))\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b40800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed representations: [ 0.03873087  0.01823613 -0.00771929]\n"
     ]
    }
   ],
   "source": [
    "user_model = UserModel()\n",
    "\n",
    "user_model.normalized_timestamp.adapt(\n",
    "    ratings.map(lambda x: x[\"timestamp\"]).batch(128))\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "  print(f\"Computed representations: {user_model(row)[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7eea09fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    max_tokens = 10_000\n",
    "\n",
    "    self.title_embedding = tf.keras.Sequential([\n",
    "      movie_title_lookup,\n",
    "      tf.keras.layers.Embedding(movie_title_lookup.vocab_size(), 32)\n",
    "    ])\n",
    "    self.title_text_embedding = tf.keras.Sequential([\n",
    "      tf.keras.layers.TextVectorization(max_tokens=max_tokens),\n",
    "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
    "      # We average the embedding of individual words to get one embedding vector\n",
    "      # per title.\n",
    "      tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.concat([\n",
    "        self.title_embedding(inputs[\"movie_title\"]),\n",
    "        self.title_text_embedding(inputs[\"movie_title\"]),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "549d1883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:vocab_size is deprecated, please use vocabulary_size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed representations: [-0.02866924 -0.01195638  0.02794746]\n"
     ]
    }
   ],
   "source": [
    "movie_model = MovieModel()\n",
    "\n",
    "movie_model.title_text_embedding.layers[0].adapt(\n",
    "    ratings.map(lambda x: x[\"movie_title\"]))\n",
    "\n",
    "for row in ratings.batch(1).take(1):\n",
    "  print(f\"Computed representations: {movie_model(row)[0, :3]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
